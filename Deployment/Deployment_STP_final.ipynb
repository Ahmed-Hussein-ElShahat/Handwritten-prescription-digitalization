{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-75DqcClIV0",
        "outputId": "2856283b-d3ab-4c13-db41-0683f0fdaeb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "!pip install transformers\n",
        "!pip install ultralytics\n",
        "!pip install pybktree\n",
        "!pip install levenshtein"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BUruSwl7dIq",
        "outputId": "6870d9f3-d794-444b-9e71-4f1cbf2462cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.122-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.122-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m130.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.122 ultralytics-thop-2.0.14\n",
            "Collecting pybktree\n",
            "  Downloading pybktree-1.1.tar.gz (4.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pybktree\n",
            "  Building wheel for pybktree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybktree: filename=pybktree-1.1-py3-none-any.whl size=4949 sha256=b7fb6e6597a296166423310b472f92a402b9e634305689b007fa28dac8cc2f3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/0f/45/d46dc0feb35ebb8a0ec98c379f5900916e9e79b62cbfc5af4f\n",
            "Successfully built pybktree\n",
            "Installing collected packages: pybktree\n",
            "Successfully installed pybktree-1.1\n",
            "Collecting levenshtein\n",
            "  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from levenshtein)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, levenshtein\n",
            "Successfully installed levenshtein-0.27.1 rapidfuzz-3.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install pyngrok\n",
        "!pip uninstall protobuf -y\n",
        "!pip install protobuf==3.20.*\n",
        "!pip install streamlit\n",
        "!pip install Pillow\n",
        "%env PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n",
        "!ngrok authtoken 2mdKor2sRARzy00rzHF4tijetfp_34n4ANTCXK9egrXRg4m3G\n",
        "\n",
        "\n",
        "#!pip install googletrans==4.0.0-rc1  # Specific version of googletrans\n",
        "!pip install streamlit-extras\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SLBHOy0-lYq5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import streamlit as st\n"
      ],
      "metadata": {
        "id": "Zlds6BCxlYna"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Start an HTTP tunnel on the default Streamlit port (8501)\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "print(f\"Public URL: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_OF59C9vKpW",
        "outputId": "8293bde4-bd97-4b6f-a64f-e09989a31d7a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://dbce-34-87-40-102.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from transformers import TrOCRProcessor\n",
        "\n",
        "print(transformers.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK6iupzi6A_p",
        "outputId": "74001c38-3b93-412b-9b22-76b4a4a7158f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.51.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "import os\n",
        "# Create a Deployment directory\n",
        "\n",
        "\n",
        "# Define download URLs using Google Drive file IDs\n",
        "image_logo = 'https://drive.google.com/file/d/1JAiZS9_yXJ4QlBPHy9OrLINq3Er-3SK0/view?usp=sharing'\n",
        "image_file = 'https://drive.google.com/file/d/1d6EKrhZQAVIcsbU2NSXXFEpXu2LNm9Zg/view?usp=drive_link'\n",
        "\n",
        "# Download .py file into Deployment folder\n",
        "gdown.download(image_logo,\n",
        "               \"team_logo.png\", quiet=False,fuzzy=True)\n",
        "\n",
        "# Download image file into Deployment folder\n",
        "gdown.download(image_file,\n",
        "               \"logo_image.jpg\", quiet=False,fuzzy=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "mj8X2HcJzw6u",
        "outputId": "60ab27ba-f0f6-4fb6-f609-67e357de8bf8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JAiZS9_yXJ4QlBPHy9OrLINq3Er-3SK0\n",
            "To: /content/team_logo.png\n",
            "100%|██████████| 71.4k/71.4k [00:00<00:00, 70.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1d6EKrhZQAVIcsbU2NSXXFEpXu2LNm9Zg\n",
            "To: /content/logo_image.jpg\n",
            "100%|██████████| 391k/391k [00:00<00:00, 84.4MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'logo_image.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import os\n",
        "import uuid\n",
        "import os\n",
        "import cv2\n",
        "import gdown\n",
        "import cProfile\n",
        "import pstats\n",
        "import streamlit as st\n",
        "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
        "from transformers.utils import logging\n",
        "import os.path\n",
        "import re\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pybktree\n",
        "import Levenshtein\n",
        "#################################\n",
        "profiler = cProfile.Profile()\n",
        "\n",
        "class RegionOCR:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initializes the PrescriptionOCR class.\n",
        "        \"\"\"\n",
        "        self.local_path = './Backend/Resources/weights/arabic_ocr_model'\n",
        "        if not os.path.exists(self.local_path):\n",
        "            self.download_arabic_model()\n",
        "\n",
        "        logging.set_verbosity_error()\n",
        "\n",
        "        # Load the OCR models here\n",
        "        self.english_processor = TrOCRProcessor.from_pretrained('microsoft/trocr-base-handwritten')\n",
        "        self.english_model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-base-handwritten')\n",
        "\n",
        "        self.arabic_processor = TrOCRProcessor.from_pretrained(self.local_path)\n",
        "        self.arabic_model = VisionEncoderDecoderModel.from_pretrained(self.local_path)\n",
        "\n",
        "    def extract_text(self, image, lang) -> str:\n",
        "        \"\"\"\n",
        "        Extracts text from the given image.\n",
        "\n",
        "        :param: image : The image to extract info from.\n",
        "\n",
        "        Returns:\n",
        "            str: The extracted text.\n",
        "        \"\"\"\n",
        "\n",
        "        if lang == 1:\n",
        "            return self.predict_eng(image)[0]\n",
        "        elif lang == 0:\n",
        "            return self.predict_ara(image)[0]\n",
        "        else:\n",
        "            return ''\n",
        "\n",
        "    def predict_ara(self, image):\n",
        "        pixel_values = self.arabic_processor(image, return_tensors=\"pt\").pixel_values\n",
        "        ids = self.arabic_model.generate(pixel_values)\n",
        "        return self.arabic_processor.batch_decode(ids, skip_special_tokens=True)\n",
        "\n",
        "    def predict_eng(self, image):\n",
        "\n",
        "        pixel_values = self.english_processor(image, return_tensors=\"pt\").pixel_values\n",
        "        ids = self.english_model.generate(pixel_values)\n",
        "        return self.english_processor.batch_decode(ids, skip_special_tokens=True)\n",
        "\n",
        "    def download_arabic_model(self):\n",
        "        \"\"\"\n",
        "        Downloads the Arabic OCR model if it does not exist locally.\n",
        "        \"\"\"\n",
        "        os.makedirs(self.local_path, exist_ok=True)\n",
        "\n",
        "        # Define the model files ID's\n",
        "        config_id = \"1-QuP1ZoXsAjJSkO2AVrXiSIdUhp3zww_\"\n",
        "        gen_config_id = \"1-ORYC4N1liybcyuDihjGSNzWqV3oSH9J\"\n",
        "        model_tensor_id = \"1-YlWSsZy0TGHwtU2eR7Ng78k0dYJuKm0\"\n",
        "        processor_id = \"1-NjWDOpHa9QHh_W5xdu-u_pfoufj7-1K\"\n",
        "        sentence_piece_id = \"1-WYclVqXwNxXMfRE5tN6K-VVjkPzyQq6\"\n",
        "        special_tokens_id = \"1-HCqIsfz56dg0V-fBs8VzGVs92sPZg8L\"\n",
        "        tokenizer_config_id = \"1-B65XNidxQNdZxW8QijJiQUmru6oHz9K\"\n",
        "        tokenizer_id = \"1-8dheZMmlG879XGsGJiMgpvgNZot6QtN\"\n",
        "\n",
        "        # Download the model files\n",
        "        gdown.download(f\"https://drive.google.com/uc?id={config_id}\",\n",
        "                       os.path.join(self.local_path, 'config.json'),\n",
        "                       quiet=False,\n",
        "                       fuzzy=True)\n",
        "        gdown.download(f\"https://drive.google.com/uc?id={gen_config_id}\",\n",
        "                       os.path.join(self.local_path, 'generation_config.json'),\n",
        "                       quiet=False,\n",
        "                       fuzzy=True)\n",
        "        gdown.download(f\"https://drive.google.com/uc?id={model_tensor_id}\",\n",
        "                       os.path.join(self.local_path, 'model.safetensors'),\n",
        "                       quiet=False,\n",
        "                       fuzzy=True)\n",
        "        gdown.download(f\"https://drive.google.com/uc?id={processor_id}\",\n",
        "                       os.path.join(self.local_path, 'preprocessor_config.json'),\n",
        "                       quiet=False,\n",
        "                       fuzzy=True)\n",
        "        gdown.download(f\"https://drive.google.com/uc?id={sentence_piece_id}\",\n",
        "                       os.path.join(self.local_path, 'sentencepiece.bpe.model'),\n",
        "                       quiet=False,\n",
        "                       fuzzy=True)\n",
        "        gdown.download(f\"https://drive.google.com/uc?id={special_tokens_id}\",\n",
        "                       os.path.join(self.local_path, 'special_tokens_map.json'),\n",
        "                       quiet=False,\n",
        "                       fuzzy=True)\n",
        "        gdown.download(f\"https://drive.google.com/uc?id={tokenizer_config_id}\",\n",
        "                       os.path.join(self.local_path, 'tokenizer_config.json'),\n",
        "                       quiet=False,\n",
        "                       fuzzy=True)\n",
        "        gdown.download(f\"https://drive.google.com/uc?id={tokenizer_id}\",\n",
        "                       os.path.join(self.local_path, 'tokenizer.json'),\n",
        "                       quiet=False,\n",
        "                       fuzzy=True)\n",
        "\n",
        "\n",
        "\n",
        "class RoiExtractor:\n",
        "    \"\"\"\n",
        "    This class is responsible for extracting regions of interest (ROIs) from images using a YOLO model.\n",
        "    It identifies specific regions in the image based on the model's predictions and categorizes them into\n",
        "    different types such as language, frequency, and medication, then extract the text from them.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initializes the RoiExtractor class.\n",
        "        It downloads the YOLO model if it does not exist locally and loads the model.\n",
        "        \"\"\"\n",
        "        self.local_path = './Backend/Resources/weights/Roi_extractor.pt'\n",
        "        if not os.path.exists(self.local_path):\n",
        "            self.download_model()\n",
        "        self.yolo = YOLO(self.local_path)\n",
        "        self.classes = self.yolo.names\n",
        "        # print(self.classes.items())\n",
        "        # Load the OCR model here\n",
        "        self.ocr = RegionOCR()\n",
        "\n",
        "    def extract_info(self, img_path):\n",
        "        \"\"\"\n",
        "        Predicts the regions of interest in the given image using the YOLO model\n",
        "        and gets the description associated with each one.\n",
        "\n",
        "        :param img: the image which should be processed\n",
        "        :return: parts of the image each one include the bounding box, the description of it and the predicted label\n",
        "        \"\"\"\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (640, 640))\n",
        "        boxes = self.get_ROI(img)\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        return self.add_lang_type(boxes, img)\n",
        "\n",
        "    def get_ROI(self, img):\n",
        "        \"\"\"\n",
        "        This function is used to get the region of interest (ROI) from the image using the YOLO model.\n",
        "\n",
        "        :param img: the image which should be processed\n",
        "        :return: bounding boxes, confidence scores and class ids\n",
        "        \"\"\"\n",
        "        # get the region of interest (ROI) from the image\n",
        "        roi = self.yolo.predict(img, conf=0.5, verbose=False)\n",
        "        w, h = img.shape[1], img.shape[0]\n",
        "\n",
        "        # print(len(roi[0]))\n",
        "        # plt.imshow(img)\n",
        "        # plt.show()\n",
        "\n",
        "        # plt.imshow(roi[0].plot())\n",
        "        # plt.show()\n",
        "        result = roi[0].obb\n",
        "        result = sorted(result, key=lambda x: x.xyxy[0][1].cpu().numpy())  # sort according to the y-axis\n",
        "\n",
        "        # get the bounding boxes, confidence scores and class ids\n",
        "        conf = []\n",
        "        xyxy = []\n",
        "        cls_ids = []\n",
        "        for res in result:\n",
        "            cls_ids.append(int(res.cls[0].cpu().numpy()))\n",
        "            conf.append(res.conf[0].cpu().numpy())\n",
        "\n",
        "            x1, y1, x2, y2 = res.xyxy[0].cpu().numpy()\n",
        "            x1, y1 ,x2, y2 = max(0, x1), max(0, y1), min(w, x2), min(h, y2)\n",
        "            x1, y1, x2, y2 = x1/w, y1/h, x2/w, y2/h\n",
        "\n",
        "            xyxy.append((x1, y1, x2, y2))\n",
        "\n",
        "        return xyxy, conf, cls_ids\n",
        "\n",
        "    def add_lang_type(self, boxes, img):\n",
        "        \"\"\"\n",
        "        This function is used to add the language and type of the prescription to the bounding boxes.\n",
        "\n",
        "        :param boxes: the bounding boxes, confidence scores and class ids\n",
        "        :param img: the image which should be processed\n",
        "        :return: parts of the image each one include the bounding box, the description of it and the predicted label\n",
        "        \"\"\"\n",
        "        bbox, conf, cls_ids = boxes\n",
        "\n",
        "        num_med = 0\n",
        "        num_freq = 0\n",
        "        num_lang = 0\n",
        "        num_types = 0\n",
        "\n",
        "        # count the number of each class\n",
        "        for i in range(len(cls_ids)):\n",
        "            if cls_ids[i] == 2:\n",
        "                num_freq += 1\n",
        "            elif cls_ids[i] == 3:\n",
        "                num_med += 1\n",
        "\n",
        "            if cls_ids[i] <= 1:\n",
        "                num_lang += 1\n",
        "            else:\n",
        "                num_types += 1\n",
        "\n",
        "        parts = []\n",
        "        frequency_index = 0\n",
        "        medicine_index = 0\n",
        "\n",
        "        remove_list = []\n",
        "        # TODO: check if the medicine number not equal to the frequency number or if prescription doesnt have a language\n",
        "        for i in range(len(bbox)):\n",
        "            best_iou, box_idx = 0, None\n",
        "            for j in range(i + 1, len(bbox)):\n",
        "                cur_iou = self.iou(bbox[i], bbox[j])\n",
        "                if cur_iou > 0.5 and cur_iou > best_iou:  # extract the info when the boxes refer to the same region\n",
        "                  best_iou, box_idx = cur_iou, j\n",
        "\n",
        "\n",
        "            # for i in range(len(parts)):\n",
        "            #   if self.iou(parts[i][0], bbox[i]) > 0.5:\n",
        "            #     continue\n",
        "            if best_iou != 0:\n",
        "                lang, prescription_type = self.get_region_info(cls_ids[i], cls_ids[box_idx])\n",
        "\n",
        "                # crop the region of interest\n",
        "                x1, y1, x2, y2 = bbox[i]\n",
        "                x1_1, y1_1, x2_1, y2_1 = int(x1*img.shape[1]), int(y1*img.shape[0]), int(x2*img.shape[1]), int(y2*img.shape[0])\n",
        "\n",
        "                x1, y1, x2, y2 = bbox[box_idx]\n",
        "                x1_2, y1_2, x2_2, y2_2 = int(x1*img.shape[1]), int(y1*img.shape[0]), int(x2*img.shape[1]), int(y2*img.shape[0])\n",
        "\n",
        "                x1 = min(x1_1, x1_2)\n",
        "                y1 = min(y1_1, y1_2)\n",
        "                x2 = max(x2_1, x2_2)\n",
        "                y2 = max(y2_1, y2_2)\n",
        "\n",
        "                cropped_img = img[y1:y2, x1:x2]\n",
        "\n",
        "                # get the label of the ROI\n",
        "                if prescription_type == 'Medicine':\n",
        "                    medicine_index += 1\n",
        "                else:\n",
        "                    frequency_index += 1\n",
        "\n",
        "                # Use the OCR to get the text\n",
        "                text = self.ocr.extract_text(cropped_img, lang)\n",
        "                label = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "                label = label.strip()\n",
        "                # plt.imshow(cropped_img)\n",
        "                # plt.show()\n",
        "                # print(label)\n",
        "                # print(\"iou:\", best_iou)\n",
        "                # print(label, self.classes.get(prescription_type), self.classes.get(lang))\n",
        "                # plt.imshow(cropped_img)\n",
        "                # plt.show()\n",
        "                # add the label with the other info into the list\n",
        "                parts.append((bbox[i], (prescription_type, lang), label))\n",
        "                    # break\n",
        "\n",
        "            if frequency_index == num_freq and medicine_index == num_med:\n",
        "                break\n",
        "\n",
        "        return parts\n",
        "\n",
        "    @staticmethod\n",
        "    def iou(b1, b2):\n",
        "        \"\"\"\n",
        "        This function is used to calculate the intersection over union (IoU) of two bounding boxes.\n",
        "\n",
        "        :param b1: the first bounding box\n",
        "        :param b2: the second bounding box\n",
        "        :return: IOU of the two bounding boxes\n",
        "        \"\"\"\n",
        "        x1, y1, x2, y2 = b1\n",
        "        x3, y3, x4, y4 = b2\n",
        "\n",
        "        # calculate the area of the two bounding boxes\n",
        "        area1 = (x2 - x1) * (y2 - y1)\n",
        "        area2 = (x4 - x3) * (y4 - y3)\n",
        "\n",
        "        # get the intersection coordinates\n",
        "        intersection_x1 = max(x1, x3)\n",
        "        intersection_y1 = max(y1, y3)\n",
        "        intersection_x2 = min(x2, x4)\n",
        "        intersection_y2 = min(y2, y4)\n",
        "\n",
        "        # calculate the area of the intersection\n",
        "        intersection_area = max(0, intersection_x2 - intersection_x1) * max(0, intersection_y2 - intersection_y1)\n",
        "\n",
        "        # calculate the area of the union\n",
        "        union_area = area1 + area2 - intersection_area\n",
        "\n",
        "        return intersection_area / union_area if union_area > 0 else 0\n",
        "\n",
        "    def get_region_info(self, id1, id2):\n",
        "        \"\"\"\n",
        "        This function is used to get the language and type of the prescription from the class ids.\n",
        "\n",
        "        :param id1: the first class id\n",
        "        :param id2: the second class id\n",
        "        :return: language and prescription type of the region.\n",
        "        \"\"\"\n",
        "        # get class names from the ids\n",
        "        class_name1 = list(self.classes.keys())[int(id1)]\n",
        "        class_name2 = list(self.classes.keys())[int(id2)]\n",
        "        # extract language and whether the region has frequency or medication\n",
        "        lang=None\n",
        "        prescription_type = None\n",
        "        if id1 <= 1:\n",
        "            lang = class_name1\n",
        "        else:\n",
        "            prescription_type = class_name1\n",
        "\n",
        "        if id2 <= 1:\n",
        "            lang = class_name2\n",
        "        else:\n",
        "            prescription_type = class_name2\n",
        "\n",
        "        return lang, prescription_type\n",
        "\n",
        "    def download_model(self):\n",
        "        \"\"\"\n",
        "        Downloads the YOLO model from Google Drive.\n",
        "        It creates the necessary directories and downloads the model file.\n",
        "        \"\"\"\n",
        "        os.makedirs(os.path.dirname(self.local_path), exist_ok=True)\n",
        "        model_link = 'https://drive.google.com/file/d/1O1gQBJUdXgEw6Ttu7p_pi63--iQVTozN/view?usp=sharing'\n",
        "        gdown.download(model_link, self.local_path, quiet=False, fuzzy=True)\n",
        "\n",
        "\n",
        "\n",
        "class PrescriptionOCR:\n",
        "    def __init__(self):\n",
        "        self.roi_extractor = RoiExtractor()\n",
        "        self.frequency_corpus_url = \"https://drive.google.com/file/d/1HAGoD0C8PnyjrpTdONfZ_p2NbgdGkaoA/view?usp=drive_link\"\n",
        "        self.medicine_corpus_url = \"https://drive.google.com/file/d/1JIKGrTHapxYicaqPHImJh74Vbt2h1the/view?usp=sharing\"\n",
        "\n",
        "        self.download_corpus()\n",
        "        medicines, frequencies = self.read_wordlist()\n",
        "\n",
        "        self.medicine_BK_tree = pybktree.BKTree(Levenshtein.distance, medicines)\n",
        "        self.frequency_BK_tree = pybktree.BKTree(Levenshtein.distance, frequencies)\n",
        "\n",
        "    def process_image(self, img_path: str) -> str:\n",
        "        \"\"\"\n",
        "        Read the image and make any needed processing before extracting text from it.\n",
        "\n",
        "        :return: preprocessed image.\n",
        "        \"\"\"\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        # Resize the image to a fixed size\n",
        "        # img = cv2.resize(img, (1024, 1024))\n",
        "        # TODO: add auto-orientation and de-skewing\n",
        "        return img\n",
        "\n",
        "    def predict(self, img_path: str) -> list:\n",
        "        \"\"\"\n",
        "        Predict the text from the image.\n",
        "\n",
        "        :return: predicted text.\n",
        "        \"\"\"\n",
        "        # Read and process the image\n",
        "        img = self.process_image(img_path)\n",
        "\n",
        "        # Get ROI from the image\n",
        "        image_parts = self.roi_extractor.extract_info(img_path)\n",
        "\n",
        "        num_freq = 0\n",
        "        num_med = 0\n",
        "        last_type = None\n",
        "        last_label = None\n",
        "        pairs = []\n",
        "        for part in image_parts:\n",
        "            # Get the bounding box coordinates\n",
        "            x1, y1, x2, y2 = part[0]\n",
        "            # Get the ROI description\n",
        "            prescription_type, lang = part[1]\n",
        "\n",
        "            # Get the text from the image\n",
        "            label = part[2]\n",
        "\n",
        "            # get the nearst right word at a maximum distance of 3\n",
        "            label, prescription_type = self.get_nearst_word_type(label, prescription_type, 5)\n",
        "            # print(prescription_type, label)\n",
        "\n",
        "            # Check if prescription type is empty\n",
        "            if prescription_type == None:\n",
        "                pairs.append([])\n",
        "                continue\n",
        "            # Check if the last type is not None\n",
        "            if last_type is not None:\n",
        "                # Check if the last type is different from the current type\n",
        "                if last_type != prescription_type:\n",
        "                    # pair is (medicine, frequency)\n",
        "                    pair = (label, last_label) if prescription_type == 3 else (last_label, label) # 3 -> medicine\n",
        "                    pairs.append(pair)\n",
        "\n",
        "                    # change last type to None\n",
        "                    last_type = None\n",
        "                else:\n",
        "                    # print(\"missing value and the current type:\", prescription_type)\n",
        "                    pair = (last_label, '') if prescription_type == 3 else ('', last_label)\n",
        "                    pairs.append(pair)\n",
        "                    last_label = label\n",
        "            else:\n",
        "                last_label = label\n",
        "                last_type = prescription_type\n",
        "        return pairs\n",
        "\n",
        "    def get_nearst_word_type(self, word: str, prescription_type: str, max_distance: int = 3) -> (str, str):\n",
        "        # get the nearst word to the given label from the appointment and the medicine corpus\n",
        "        frequency = self.get_nearst_word(word, self.frequency_BK_tree, 3)\n",
        "        medicine = self.get_nearst_word(word, self.medicine_BK_tree, 3)\n",
        "\n",
        "        # check if the word is in the medicine or frequency corpus\n",
        "        if medicine is not None and frequency is not None:\n",
        "            # check which one is the nearest\n",
        "            if medicine[0] < frequency[0]:\n",
        "                label = medicine[1]\n",
        "                prescription_type = 3  #  3 -> medicine\n",
        "            elif frequency[0] < medicine[0]:\n",
        "                label = frequency[1]\n",
        "                prescription_type = 2  #  2 -> frequency\n",
        "            else:  # if they are equal then check the prescription type\n",
        "                label = medicine[1] if prescription_type == 3 else frequency[1]\n",
        "        elif medicine is not None:\n",
        "            label = medicine[1]\n",
        "            prescription_type = 3\n",
        "        elif frequency is not None:\n",
        "            label = frequency[1]\n",
        "            prescription_type = 2\n",
        "        else:  # if not in corpus then return the word itself\n",
        "            label = word\n",
        "        return label, prescription_type\n",
        "\n",
        "    def get_nearst_word(self, word: str, bk_tree, max_distance: int = 3) -> str | None:\n",
        "        \"\"\"\n",
        "        Get the nearest word to the given word from the medicine corpus.\n",
        "\n",
        "        :param word: The word to find the nearest word for.\n",
        "        :param bk_tree: The BK-tree to search in.\n",
        "        :param max_distance: The maximum distance to consider.\n",
        "        :return: The nearest word.\n",
        "        \"\"\"\n",
        "        nearest_word = bk_tree.find(word, max_distance)\n",
        "        if len(nearest_word) > 0:\n",
        "            return nearest_word[0]\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def download_corpus(self):\n",
        "        if not os.path.exists(\"./Backend/Resources/frequency.txt\"):\n",
        "            # Download the appointment corpus\n",
        "            frequency_corpus_local_path = \"./Backend/Resources/frequency.txt\"\n",
        "            gdown.download(self.frequency_corpus_url, frequency_corpus_local_path, quiet=False, fuzzy=True)\n",
        "\n",
        "        if not os.path.exists(\"./Backend/Resources/medicine.txt\"):\n",
        "            # Download the medicine corpus\n",
        "            medicine_corpus_local_path = \"./Backend/Resources/medicine.txt\"\n",
        "            gdown.download(self.medicine_corpus_url, medicine_corpus_local_path, quiet=False, fuzzy=True)\n",
        "\n",
        "    def read_wordlist(self):\n",
        "        \"\"\"\n",
        "        Read the medicine and frequency files and return a two list of words.\n",
        "        \"\"\"\n",
        "        with open(\"./Backend/Resources/medicine.txt\", \"r\") as f:\n",
        "            medicines = f.read().splitlines()\n",
        "\n",
        "        with open(\"./Backend/Resources/frequency.txt\", \"r\") as f:\n",
        "            frequencies = f.read().splitlines()\n",
        "        return medicines, frequencies\n",
        "\n",
        "################################\n",
        "# Create a temporary folder to store uploaded images\n",
        "TEMP_DIR = \"temp_uploads\"\n",
        "os.makedirs(TEMP_DIR, exist_ok=True)\n",
        "\n",
        "# Set Streamlit page config\n",
        "st.set_page_config(page_title=\"PharmaLens\", layout=\"centered\")\n",
        "# Custom CSS to make the sidebar background grey\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "    <style>\n",
        "        /* Sidebar styling */\n",
        "        [data-testid=\"stSidebar\"] {\n",
        "            background-color: #f0f0f0;\n",
        "        }\n",
        "\n",
        "        [data-testid=\"stSidebar\"] h1,\n",
        "        [data-testid=\"stSidebar\"] h2,\n",
        "        [data-testid=\"stSidebar\"] h3,\n",
        "        [data-testid=\"stSidebar\"] p {\n",
        "            color: #333;\n",
        "        }\n",
        "\n",
        "        /* File uploader label */\n",
        "        [data-testid=\"stFileUploaderLabel\"] {\n",
        "            color: white !important;\n",
        "            font-size: 16px !important;\n",
        "        }\n",
        "\n",
        "        /* Image caption override (if used) */\n",
        "        .css-1hsbpi5 {\n",
        "            color: white !important;\n",
        "            font-size: 16px !important;\n",
        "        }\n",
        "\n",
        "        /* Submit button */\n",
        "        button[kind=\"primary\"] {\n",
        "            color: white !important;\n",
        "            font-size: 18px !important;\n",
        "        }\n",
        "\n",
        "        /* Extracted result text */\n",
        "        .extracted-text {\n",
        "            color: white !important;\n",
        "            font-size: 20px !important;\n",
        "        }\n",
        "\n",
        "        .result-box {\n",
        "            background-color: #2d2d2d;\n",
        "            padding: 10px;\n",
        "            border-radius: 8px;\n",
        "            margin-bottom: 10px;\n",
        "        }\n",
        "\n",
        "        /* Success message styling */\n",
        "        [data-testid=\"stAlert-success\"] {\n",
        "            background-color: #2d2d2d !important;\n",
        "            color: white !important;\n",
        "            font-size: 18px !important;\n",
        "            border-left: 6px solid #1db954;\n",
        "        }\n",
        "    </style>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        ")\n",
        "\n",
        "\n",
        "# Title and Logo layout\n",
        "col1, col2 = st.columns([4, 1])\n",
        "with col1:\n",
        "    st.title(\"PharmaLens🔬🔍\")\n",
        "with col2:\n",
        "    st.image(\"logo_image.jpg\", use_container_width=True)  # Make sure this exists in the working directory\n",
        "\n",
        "\n",
        "# Sidebar with team name/logo\n",
        "    with st.sidebar:\n",
        "        #st.markdown(\"## 🧠 Team MedVision\")\n",
        "        st.write(\"AI-powered Prescription OCR System\")\n",
        "        # Optional: logo image if you have it\n",
        "        st.image(\"team_logo.png\", width=150)\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(\"### 📇 Connect with Us\")\n",
        "\n",
        "        st.markdown(\n",
        "            \"\"\"\n",
        "            <ul style='padding-left: 1em;'>\n",
        "                <li><a href=\"https://www.linkedin.com/in/kareem-wael-k918/\" target=\"_blank\" style=\"text-decoration: none; color: #0e76a8;\">Kareem Wael</a></li>\n",
        "                <li><a href=\"https://www.linkedin.com/in/azza-hassan-40097a276/\" target=\"_blank\" style=\"text-decoration: none; color: #0e76a8;\">Azza Hassan Said</a></li>\n",
        "                <li><a href=\"https://www.linkedin.com/in/ahmed-hussein-el-shahat/\" target=\"_blank\" style=\"text-decoration: none; color: #0e76a8;\">Ahmed Hussien</a></li>\n",
        "            </ul>\n",
        "            \"\"\",\n",
        "            unsafe_allow_html=True\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# File uploader\n",
        "st.markdown(\"<p style='color:white; font-size:16px;'>Upload a medical prescription image</p>\", unsafe_allow_html=True)\n",
        "uploaded_file = st.file_uploader(\"\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "\n",
        "\n",
        "# Define submit function from user\n",
        "def submit(images):\n",
        "    \"\"\"\n",
        "    Processes a list of prescription images and extracts structured prescription data.\n",
        "    Args:\n",
        "        images (list of str): List of file paths to input prescription images.\n",
        "    Returns:\n",
        "        list of list of tuples: Each inner list contains (medicine, frequency) pairs.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    ocr = PrescriptionOCR()\n",
        "    for img_path in images:\n",
        "        try:\n",
        "            prescription_data = ocr.predict(img_path)\n",
        "            results.append(prescription_data)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error processing image {img_path}: {e}\")\n",
        "            results.append([])\n",
        "    return results\n",
        "\n",
        "# Main logic\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file)\n",
        "    st.image(image, caption=None, use_container_width=True)  # Hide default caption\n",
        "    st.markdown(\"<p style='color:white; font-size:16px;'>Uploaded Image</p>\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "    if st.button(\"🧾Submit Prescription\"):\n",
        "        # Save uploaded image temporarily\n",
        "        with st.spinner(\"Extracting information...\"):\n",
        "                temp_filename = f\"{uuid.uuid4().hex}.png\"\n",
        "                temp_path = os.path.join(TEMP_DIR, temp_filename)\n",
        "                image.save(temp_path)\n",
        "\n",
        "                # Call submit with the temp path\n",
        "                all_results = submit([temp_path])  # List of 1 image\n",
        "\n",
        "        st.success(\"✅ Extraction complete!\")\n",
        "        if all_results and all_results[0]:\n",
        "            st.subheader(\"Extracted Information\")\n",
        "            for med, freq in all_results[0]:\n",
        "              st.markdown(\n",
        "                  f\"\"\"\n",
        "                  <div class=\"result-box\">\n",
        "                      <div class=\"extracted-text\">\n",
        "                          <strong>Medicine:</strong> {med}<br>\n",
        "                          <strong>Frequency dosage:</strong> {freq if freq else 'Not specified'}\n",
        "                      </div>\n",
        "                  </div>\n",
        "                  \"\"\",\n",
        "                  unsafe_allow_html=True\n",
        "              )\n",
        "\n",
        "        # Cleanup temp file\n",
        "        os.remove(temp_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJUME1ys1cK8",
        "outputId": "c824eaf4-bc3e-4ef2-830f-100fb76b809b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlvdvePeDzYa",
        "outputId": "7f30cb79-3ad5-4a99-a781-c79c1dc865a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.87.40.102:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2025-05-01 19:42:59.041 Uncaught exception GET /_stcore/stream (127.0.0.1)\n",
            "HTTPServerRequest(protocol='http', host='dbce-34-87-40-102.ngrok-free.app', method='GET', uri='/_stcore/stream', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tornado/websocket.py\", line 938, in _accept_connection\n",
            "    open_result = handler.open(*handler.open_args, **handler.open_kwargs)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/server/browser_websocket_handler.py\", line 177, in open\n",
            "    self._session_id = self._runtime.connect_session(\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/runtime/runtime.py\", line 384, in connect_session\n",
            "    session_id = self._session_mgr.connect_session(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/runtime/websocket_session_manager.py\", line 99, in connect_session\n",
            "    session = AppSession(\n",
            "              ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/runtime/app_session.py\", line 158, in __init__\n",
            "    self.register_file_watchers()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/runtime/app_session.py\", line 195, in register_file_watchers\n",
            "    self._local_sources_watcher = LocalSourcesWatcher(self._pages_manager)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 65, in __init__\n",
            "    self.update_watched_pages()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 77, in update_watched_pages\n",
            "    self._register_watcher(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 136, in _register_watcher\n",
            "    watcher=PathWatcher(filepath, self.on_file_changed),\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/event_based_path_watcher.py\", line 107, in __init__\n",
            "    path_watcher.watch_path(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/event_based_path_watcher.py\", line 185, in watch_path\n",
            "    folder_handler.watch = self._observer.schedule(\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/watchdog/observers/api.py\", line 312, in schedule\n",
            "    emitter.start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/watchdog/utils/__init__.py\", line 75, in start\n",
            "    self.on_thread_start()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/watchdog/observers/inotify.py\", line 119, in on_thread_start\n",
            "    self._inotify = InotifyBuffer(path, recursive=self.watch.is_recursive, event_mask=event_mask)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/watchdog/observers/inotify_buffer.py\", line 30, in __init__\n",
            "    self._inotify = Inotify(path, recursive=recursive, event_mask=event_mask)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/watchdog/observers/inotify_c.py\", line 185, in __init__\n",
            "    self._add_dir_watch(path, event_mask, recursive=recursive)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/watchdog/observers/inotify_c.py\", line 411, in _add_dir_watch\n",
            "    self._add_watch(full_path, mask)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/watchdog/observers/inotify_c.py\", line 424, in _add_watch\n",
            "    Inotify._raise_error()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/watchdog/observers/inotify_c.py\", line 441, in _raise_error\n",
            "    raise OSError(err, os.strerror(err))\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n",
            "Exception ignored in: <function AppSession.__del__ at 0x7bc7fc3a3c40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/runtime/app_session.py\", line 178, in __del__\n",
            "    self.shutdown()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/runtime/app_session.py\", line 255, in shutdown\n",
            "    self.request_script_stop()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/runtime/app_session.py\", line 428, in request_script_stop\n",
            "    if self._scriptrunner is not None:\n",
            "       ^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'AppSession' object has no attribute '_scriptrunner'\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746128586.407908   24723 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746128586.415468   24723 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-01 19:43:11.708 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-05-01 19:43:12.413 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "2025-05-01 19:43:42.484 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-05-01 19:44:04.034 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n",
            "2025-05-01 19:44:26.655 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "2025-05-01 19:49:45.210 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-05-01 19:49:46.172 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "2025-05-01 19:50:13.402 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-05-01 19:50:23.001 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-05-01 19:52:01.192 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-05-01 19:52:02.570 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "2025-05-01 19:52:13.271 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-05-01 19:56:09.247 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-05-01 19:56:21.141 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-05-01 20:07:33.976 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2025-05-01 20:07:35.055 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 347, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5JS_lS3Eimt8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}